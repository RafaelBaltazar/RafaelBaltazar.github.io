{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9XC2ErmtIoT"
      },
      "source": [
        "**IMPORTING DATA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5l8dn7QTedJ",
        "outputId": "7244715e-ee3a-4272-8a83-451e16e36c47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/yfinance/base.py:48: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "  _empty_series = pd.Series()\n",
            "[*********************100%%**********************]  1 of 1 completed\n"
          ]
        }
      ],
      "source": [
        "import yfinance as yf\n",
        "\n",
        "# Define the ticker symbol for S&P 500 (SPY is the ETF that tracks it)\n",
        "ticker_symbol = \"SPY\"\n",
        "\n",
        "# Define the start and end dates for your data\n",
        "start_date = \"2000-12-01\"\n",
        "end_date = \"2023-09-01\"\n",
        "\n",
        "# Fetch historical S&P 500 data from Yahoo Finance\n",
        "sp500_data = yf.download(ticker_symbol, start=start_date, end=end_date)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b96-f59wWwsB",
        "outputId": "82208dc0-4ebc-463e-c80b-91baad50dd1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fredapi\n",
            "  Downloading fredapi-0.5.1-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from fredapi) (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->fredapi) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->fredapi) (2023.4)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas->fredapi) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->fredapi) (1.16.0)\n",
            "Installing collected packages: fredapi\n",
            "Successfully installed fredapi-0.5.1\n"
          ]
        }
      ],
      "source": [
        "pip install fredapi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "LcwCUClvV0M5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "outputId": "b7d47ecc-c6b4-403d-e352-b9f28065fa6c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "You need to set a valid API key. You can set it in 3 ways:\npass the string with api_key, or set api_key_file to a\nfile with the api key in the first line, or set the\nenvironment variable 'FRED_API_KEY' to the value of your\napi key. You can sign up for a free api key on the Fred\nwebsite at http://research.stlouisfed.org/fred2/",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-ebd0c0aa00b2>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Initialize the FRED API client with your API key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mfred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Define the series IDs for the economic indicators you want to retrieve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/fredapi/fred.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, api_key, api_key_file)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mtextwrap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             raise ValueError(textwrap.dedent(\"\"\"\\\n\u001b[0m\u001b[1;32m     51\u001b[0m                     \u001b[0mYou\u001b[0m \u001b[0mneed\u001b[0m \u001b[0mto\u001b[0m \u001b[0mset\u001b[0m \u001b[0ma\u001b[0m \u001b[0mvalid\u001b[0m \u001b[0mAPI\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mYou\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mset\u001b[0m \u001b[0mit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0mways\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                     \u001b[0;32mpass\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mstring\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mapi_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mset\u001b[0m \u001b[0mapi_key_file\u001b[0m \u001b[0mto\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: You need to set a valid API key. You can set it in 3 ways:\npass the string with api_key, or set api_key_file to a\nfile with the api key in the first line, or set the\nenvironment variable 'FRED_API_KEY' to the value of your\napi key. You can sign up for a free api key on the Fred\nwebsite at http://research.stlouisfed.org/fred2/"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from fredapi import Fred\n",
        "\n",
        "# Retrieve API key from environment variable\n",
        "api_key = os.environ.get('FRED_API_KEY')\n",
        "\n",
        "# Initialize the FRED API client with your API key\n",
        "fred = Fred(api_key=api_key)\n",
        "\n",
        "# Define the series IDs for the economic indicators you want to retrieve\n",
        "inflation_series_id = 'CPIAUCSL'  # Consumer Price Index for All Urban Consumers (CPI-U)\n",
        "interest_rate_series_id = 'FEDFUNDS'  # Effective Federal Funds Rate\n",
        "labor_openings_series_id = 'JTSJOL'  # Job Openings\n",
        "\n",
        "# Fetch economic indicator data from FRED\n",
        "inflation_data = fred.get_series(inflation_series_id, start=start_date, end=end_date)\n",
        "interest_rate_data = fred.get_series(interest_rate_series_id, start=start_date, end=end_date)\n",
        "labor_openings_data = fred.get_series(labor_openings_series_id, start=start_date, end=end_date)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eUWlaFylZDU_"
      },
      "outputs": [],
      "source": [
        "inflation_data.head(100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lDigqkn3ZL6g"
      },
      "outputs": [],
      "source": [
        "interest_rate_data.head(100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5TkshD3TZXa3"
      },
      "outputs": [],
      "source": [
        "labor_openings_data.head(100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xjof2Q7EdLum"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a figure and subplots for S&P 500 and economic data\n",
        "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 8))\n",
        "\n",
        "# Plot S&P 500 data\n",
        "axes[0, 0].plot(sp500_data.index, sp500_data['Close'], label='S&P 500', color='blue')\n",
        "axes[0, 0].set_title('S&P 500')\n",
        "axes[0, 0].set_xlabel('Date')\n",
        "axes[0, 0].set_ylabel('Price')\n",
        "\n",
        "# Plot inflation data\n",
        "axes[0, 1].plot(inflation_data.index, inflation_data, label='Inflation Rate', color='green')\n",
        "axes[0, 1].set_title('Inflation Rate')\n",
        "axes[0, 1].set_xlabel('Date')\n",
        "axes[0, 1].set_ylabel('Rate')\n",
        "\n",
        "# Plot interest rate data\n",
        "axes[1, 0].plot(interest_rate_data.index, interest_rate_data, label='Interest Rate', color='red')\n",
        "axes[1, 0].set_title('Interest Rate')\n",
        "axes[1, 0].set_xlabel('Date')\n",
        "axes[1, 0].set_ylabel('Rate')\n",
        "\n",
        "# Plot labor openings data\n",
        "axes[1, 1].plot(labor_openings_data.index, labor_openings_data, label='Labor Openings', color='purple')\n",
        "axes[1, 1].set_title('Labor Openings')\n",
        "axes[1, 1].set_xlabel('Date')\n",
        "axes[1, 1].set_ylabel('Number of Openings')\n",
        "\n",
        "# Adjust layout and display legends\n",
        "plt.tight_layout()\n",
        "plt.legend()\n",
        "\n",
        "# Show the plots\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f1fM7vB-trbL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Convert the economic data Series to DataFrames with appropriate column names\n",
        "inflation_df = pd.DataFrame({'Inflation_Rate': inflation_data})\n",
        "interest_rate_df = pd.DataFrame({'Interest_Rate': interest_rate_data})\n",
        "labor_openings_df = pd.DataFrame({'Labor_Openings': labor_openings_data})\n",
        "\n",
        "# Merge the DataFrames with your S&P 500 data\n",
        "merged_data = sp500_data.join([inflation_df, interest_rate_df, labor_openings_df], how='inner')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "igVs9gcHdiK-"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "\n",
        "# Create a DataFrame containing all the data you want to analyze\n",
        "# In this case, we'll use the merged_data DataFrame\n",
        "data_to_analyze = merged_data[['Close', 'Inflation_Rate', 'Interest_Rate', 'Labor_Openings']]\n",
        "\n",
        "# Calculate the correlation matrix\n",
        "correlation_matrix = data_to_analyze.corr()\n",
        "\n",
        "# Create a heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)\n",
        "plt.title('Correlation Heatmap')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4vixWXCsXwNp"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "idh0pg2DXRHg"
      },
      "outputs": [],
      "source": [
        "# Convert the economic data Series to DataFrames with appropriate column names\n",
        "inflation_df = pd.DataFrame({'Inflation_Rate': inflation_data})\n",
        "interest_rate_df = pd.DataFrame({'Interest_Rate': interest_rate_data})\n",
        "labor_openings_df = pd.DataFrame({'Labor_Openings': labor_openings_data})\n",
        "\n",
        "# Merge the DataFrames with your S&P 500 data\n",
        "merged_data = sp500_data.join([inflation_df, interest_rate_df, labor_openings_df], how='inner')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLc1P_Q2XE0B"
      },
      "outputs": [],
      "source": [
        "# Calculate 7-day rolling mean and standard deviation of S&P 500 prices\n",
        "merged_data['SMA_7'] = merged_data['Close'].rolling(window=7).mean()\n",
        "merged_data['STD_7'] = merged_data['Close'].rolling(window=7).std()\n",
        "\n",
        "# Calculate percentage change in S&P 500 prices\n",
        "merged_data['Price_Change'] = merged_data['Close'].pct_change()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8haa9xsEasmv"
      },
      "outputs": [],
      "source": [
        "merged_data = merged_data.iloc[6:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ki3nxv0WYn9I"
      },
      "outputs": [],
      "source": [
        "merged_data.head(100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0RmWOxssYDia"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define your features and target variable\n",
        "X = merged_data[['SMA_7', 'STD_7', 'Inflation_Rate', 'Interest_Rate', 'Labor_Openings']]\n",
        "y = merged_data['Price_Change']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.8, random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jibvdx72fmPc"
      },
      "source": [
        "**LINEAR REGRESSION MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qDq09Ifki5ZE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf\n",
        "\n",
        "# Set a random seed for NumPy\n",
        "np.random.seed(42)\n",
        "\n",
        "# Set a random seed for Python's random module\n",
        "random.seed(42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "McU8T658YMd3"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Create a Linear Regression model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Fit the model to the training data\n",
        "model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ifPF-VcibVsg"
      },
      "outputs": [],
      "source": [
        "# Predict the price change for the test data\n",
        "lr_predictions = model.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "shKbPmebbgK3"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "# Calculate MAE and MSE\n",
        "lr_mae = mean_absolute_error(y_test, lr_predictions)\n",
        "lr_mse = mean_squared_error(y_test, lr_predictions)\n",
        "\n",
        "print(f'lr_MAE: {lr_mae}')\n",
        "print(f'lr_MSE: {lr_mse}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78BB8KNccLNd"
      },
      "outputs": [],
      "source": [
        "# Define a threshold for predictions (e.g., 0.01 for a small price change)\n",
        "threshold = 0.01\n",
        "\n",
        "# Calculate the direction of the price change based on the threshold\n",
        "y_test_direction = np.where(y_test > threshold, 1, np.where(y_test < -threshold, -1, 0))\n",
        "predictions_direction = np.where(lr_predictions > threshold, 1, np.where(lr_predictions < -threshold, -1, 0))\n",
        "\n",
        "# Calculate the precision and accuracy\n",
        "lr_precision = np.sum((y_test_direction == 1) & (predictions_direction == 1)) / np.sum(predictions_direction == 1)\n",
        "lr_accuracy = np.sum(y_test_direction == predictions_direction) / len(predictions_direction)\n",
        "\n",
        "# Calculate the Z-score of the accuracy\n",
        "n = len(predictions_direction)\n",
        "lr_z_score = (lr_accuracy - 0.5) / np.sqrt((0.5 * (1 - 0.5)) / n)\n",
        "\n",
        "print(f'lr_Precision: {lr_precision}')\n",
        "print(f'lr_Accuracy: {lr_accuracy}')\n",
        "print(f'lr_Z-score: {lr_z_score}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiptyyxTfv58"
      },
      "source": [
        "**RANDOM FOREST MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFY2VUbmfzum"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Create a Random Forests model\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "# Fit the model to the training data\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict the price change for the test data\n",
        "rf_predictions = rf_model.predict(X_test)\n",
        "\n",
        "# Calculate MAE and MSE for Random Forests\n",
        "rf_mae = mean_absolute_error(y_test, rf_predictions)\n",
        "rf_mse = mean_squared_error(y_test, rf_predictions)\n",
        "\n",
        "print(\"Random Forests Model:\")\n",
        "print(f'rf_MAE: {rf_mae}')\n",
        "print(f'rf_MSE: {rf_mse}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kyJGu7K1gHfl"
      },
      "outputs": [],
      "source": [
        "# Define a threshold for predictions (e.g., 0.01 for a small price change)\n",
        "threshold = 0.01\n",
        "\n",
        "# Calculate the direction of the price change based on the threshold\n",
        "y_test_direction = np.where(y_test > threshold, 1, np.where(y_test < -threshold, -1, 0))\n",
        "predictions_direction = np.where(rf_predictions > threshold, 1, np.where(rf_predictions < -threshold, -1, 0))\n",
        "\n",
        "# Calculate the precision and accuracy\n",
        "rf_precision = np.sum((y_test_direction == 1) & (predictions_direction == 1)) / np.sum(predictions_direction == 1)\n",
        "rf_accuracy = np.sum(y_test_direction == predictions_direction) / len(predictions_direction)\n",
        "\n",
        "# Calculate the Z-score of the accuracy\n",
        "n = len(predictions_direction)\n",
        "rf_z_score = (rf_accuracy - 0.5) / np.sqrt((0.5 * (1 - 0.5)) / n)\n",
        "\n",
        "print(f'rf_Precision: {rf_precision}')\n",
        "print(f'rf_Accuracy: {rf_accuracy}')\n",
        "print(f'rf_Z-score: {rf_z_score}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSpiYXkAgYgl"
      },
      "source": [
        "**LONG SHORT-TERM MEMORY MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZnnTxtoaghaW"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense\n",
        "\n",
        "# Reshape data for LSTM (samples, time steps, features)\n",
        "X_train_lstm = X_train.values.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
        "X_test_lstm = X_test.values.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
        "\n",
        "# Create an LSTM model\n",
        "lstm_model = Sequential()\n",
        "lstm_model.add(LSTM(50, input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2])))\n",
        "lstm_model.add(Dense(1))\n",
        "lstm_model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "# Fit the LSTM model to the training data\n",
        "lstm_model.fit(X_train_lstm, y_train, epochs=50, batch_size=32, verbose=0)\n",
        "\n",
        "# Predict the price change for the test data using the LSTM model\n",
        "lstm_predictions = lstm_model.predict(X_test_lstm).flatten()\n",
        "\n",
        "# Calculate MAE and MSE for LSTM\n",
        "lstm_mae = mean_absolute_error(y_test, lstm_predictions)\n",
        "lstm_mse = mean_squared_error(y_test, lstm_predictions)\n",
        "\n",
        "print(\"LSTM Model:\")\n",
        "print(f'lstm_MAE: {lstm_mae}')\n",
        "print(f'lstm_MSE: {lstm_mse}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pfACEBUPjeIr"
      },
      "outputs": [],
      "source": [
        "# Define a threshold for predictions (e.g., 0.01 for a small price change)\n",
        "threshold = 0.01\n",
        "\n",
        "# Calculate the direction of the price change based on the threshold\n",
        "y_test_direction = np.where(y_test > threshold, 1, np.where(y_test < -threshold, -1, 0))\n",
        "predictions_direction = np.where(lstm_predictions > threshold, 1, np.where(lstm_predictions < -threshold, -1, 0))\n",
        "\n",
        "# Calculate the precision and accuracy\n",
        "lstm_precision = np.sum((y_test_direction == 1) & (predictions_direction == 1)) / np.sum(predictions_direction == 1)\n",
        "lstm_accuracy = np.sum(y_test_direction == predictions_direction) / len(predictions_direction)\n",
        "\n",
        "# Calculate the Z-score of the accuracy\n",
        "lstm_n = len(predictions_direction)\n",
        "lstm_z_score = (lstm_accuracy - 0.5) / np.sqrt((0.5 * (1 - 0.5)) / n)\n",
        "\n",
        "print(f'lstm_Precision: {lstm_precision}')\n",
        "print(f'lstm_Accuracy: {lstm_accuracy}')\n",
        "print(f'lstm_Z-score: {lstm_z_score}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_8FlTf6lE2w"
      },
      "outputs": [],
      "source": [
        "# Create a dictionary to store the scores for each model\n",
        "scores = {\n",
        "    'Model': ['Linear Regression', 'Random Forests', 'LSTM'],\n",
        "    'MAE': [lr_mae, rf_mae, lstm_mae],\n",
        "    'MSE': [lr_mse, rf_mse, lstm_mse],\n",
        "    'Z-Score': [lr_z_score, rf_z_score, lstm_z_score],\n",
        "    'Accuracy': [lr_accuracy, rf_accuracy, lstm_accuracy],\n",
        "    'Precision': [lr_precision, rf_precision, lstm_precision]\n",
        "}\n",
        "\n",
        "# Create a DataFrame from the scores dictionary\n",
        "scores_df = pd.DataFrame(scores)\n",
        "\n",
        "# Display the comparison table\n",
        "print(scores_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aSzMczbGyftr"
      },
      "outputs": [],
      "source": [
        "# Data for 0.8 fit sampling\n",
        "data_0p8 = {\n",
        "    'Model': ['Linear Regression', 'Random Forests', 'LSTM'],\n",
        "    'MAE': [0.044526, 0.043300, 0.048092],\n",
        "    'MSE': [0.003572, 0.003560, 0.003439],\n",
        "    'Z-Score': [-2.057983, -0.685994, -4.801960],\n",
        "    'Accuracy': [0.411765, 0.470588, 0.294118],\n",
        "    'Precision': [0.537313, 0.587500, None]\n",
        "}\n",
        "\n",
        "# Data for 0.5 fit sampling\n",
        "data_0p5 = {\n",
        "    'Model': ['Linear Regression', 'Random Forests', 'LSTM'],\n",
        "    'MAE': [0.037967, 0.040806, 0.036507],\n",
        "    'MSE': [0.002284, 0.002798, 0.002158],\n",
        "    'Z-Score': [-2.494700, -1.626978, 0.325396],\n",
        "    'Accuracy': [0.364706, 0.411765, 0.517647],\n",
        "    'Precision': [0.536585, 0.543478, 0.517647]\n",
        "}\n",
        "\n",
        "# Data for 0.2 fit sampling\n",
        "data_0p2 = {\n",
        "    'Model': ['Linear Regression', 'Random Forests', 'LSTM'],\n",
        "    'MAE': [0.038565, 0.049855, 0.036391],\n",
        "    'MSE': [0.002421, 0.003780, 0.002001],\n",
        "    'Z-Score': [-1.028992, -2.057983, -3.429972],\n",
        "    'Accuracy': [0.411765, 0.323529, 0.205882],\n",
        "    'Precision': [0.473684, 0.450000, None]\n",
        "}\n",
        "\n",
        "# Create DataFrames for each fit sampling size\n",
        "df_0p8 = pd.DataFrame(data_0p8)\n",
        "df_0p5 = pd.DataFrame(data_0p5)\n",
        "df_0p2 = pd.DataFrame(data_0p2)\n",
        "\n",
        "# Display the comparison tables\n",
        "print(\"\\nFitting 0.8:\")\n",
        "print(df_0p8)\n",
        "\n",
        "print(\"\\nFitting 0.5:\")\n",
        "print(df_0p5)\n",
        "\n",
        "print(\"\\nFitting 0.2:\")\n",
        "print(df_0p2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "li_bqT-O-Ghh"
      },
      "source": [
        "**PLOTTING RESULTS**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LINEAR REGRESSION"
      ],
      "metadata": {
        "id": "eoAhu1I3ZUQ1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_YkvGQr0krT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set a random seed for NumPy\n",
        "np.random.seed(42)\n",
        "\n",
        "# Set a random seed for Python's random module\n",
        "random.seed(42)\n",
        "\n",
        "# Define the fitting values from 0.1 to 0.8 with a step of 0.1\n",
        "fitting_values = np.arange(0.1, 0.9, 0.1)\n",
        "\n",
        "# Initialize empty lists to store the differences in scores\n",
        "lr_mae_differences = []\n",
        "lr_mse_differences = []\n",
        "lr_z_score_differences = []\n",
        "lr_accuracy_differences = []\n",
        "lr_precision_differences = []\n",
        "lr_recall_differences = []\n",
        "\n",
        "# Loop through fitting values and calculate scores\n",
        "for i in range(len(fitting_values) - 1):\n",
        "    # Define the fitting value for this iteration\n",
        "    fitting_value = fitting_values[i]\n",
        "\n",
        "    # Split the data into training and testing sets with the current fitting value\n",
        "    X_train_sampled, X_test_sampled, y_train_sampled, y_test_sampled = train_test_split(\n",
        "        X, y, test_size=fitting_value, random_state=42\n",
        "    )\n",
        "\n",
        "    # Create a Linear Regression lr_model\n",
        "    lr_model = LinearRegression()\n",
        "\n",
        "    # Fit the lr_model to the training data\n",
        "    lr_model.fit(X_train_sampled, y_train_sampled)\n",
        "\n",
        "    # Predict the price change for the test data\n",
        "    lr_predictions = lr_model.predict(X_test_sampled)\n",
        "\n",
        "    # Define a threshold for predictions (e.g., 0.01 for a small price change)\n",
        "    threshold = 0.01\n",
        "\n",
        "    # Calculate the direction of the price change based on the threshold\n",
        "    y_test_direction = np.where(y_test_sampled > threshold, 1, np.where(y_test_sampled < -threshold, -1, 0))\n",
        "    lr_predictions_direction = np.where(lr_predictions > threshold, 1, np.where(lr_predictions < -threshold, -1, 0))\n",
        "\n",
        "    # Calculate MAE and MSE for the lr_predictions\n",
        "    lr_mae_score = mean_absolute_error(y_test_sampled, lr_predictions)\n",
        "    lr_mse_score = mean_squared_error(y_test_sampled, lr_predictions)\n",
        "\n",
        "    # Calculate Z-score, accuracy, and precision\n",
        "    lr_z_score = (accuracy_score(y_test_direction, lr_predictions_direction) - 0.5) / np.sqrt(\n",
        "        (0.5 * (1 - 0.5)) / len(y_test_sampled)\n",
        "    )\n",
        "    lr_accuracy = accuracy_score(y_test_direction, lr_predictions_direction)\n",
        "    lr_precision = precision_score(y_test_direction, lr_predictions_direction, average='micro')  # Use binary average\n",
        "    lr_recall = recall_score(y_test_direction, lr_predictions_direction, average='micro')\n",
        "\n",
        "    # Append the differences to the lists\n",
        "    lr_mae_differences.append(lr_mae_score)\n",
        "    lr_mse_differences.append(lr_mse_score)\n",
        "    lr_z_score_differences.append(lr_z_score)\n",
        "    lr_accuracy_differences.append(lr_accuracy)\n",
        "    lr_precision_differences.append(lr_precision)\n",
        "    lr_recall_differences.append(lr_recall)\n",
        "\n",
        "# Create a line chart to visualize the differences with colorblind-friendly colors\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.plot(fitting_values[:-1], lr_mae_differences, label='MAE Difference', marker='o', color='tab:cyan')\n",
        "plt.plot(fitting_values[:-1], lr_mse_differences, label='MSE Difference', marker='o', color='tab:gray')\n",
        "plt.plot(fitting_values[:-1], lr_z_score_differences, label='Z-Score Difference', marker='o', color='tab:purple')\n",
        "plt.plot(fitting_values[:-1], lr_accuracy_differences, label='Accuracy Difference', marker='o', color='tab:red')\n",
        "plt.plot(fitting_values[:-1], lr_precision_differences, label='Precision Difference', marker='o', color='tab:pink')\n",
        "plt.plot(fitting_values[:-1], lr_recall_differences, label='Recall Difference', marker='o', color='tab:orange')\n",
        "plt.xlabel('Fitting Values')\n",
        "plt.ylabel('Score Difference')\n",
        "plt.title('Score Differences for Linear Regression')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-Fb8B8fzcTyQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RANDOM FOREST"
      ],
      "metadata": {
        "id": "BFHIeAXpZg5o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize empty lists to store the differences in scores for Random Forest\n",
        "rf_mae_differences = []\n",
        "rf_mse_differences = []\n",
        "rf_z_score_differences = []\n",
        "rf_accuracy_differences = []\n",
        "rf_precision_differences = []\n",
        "rf_recall_differences = []\n",
        "\n",
        "# Loop through fitting values and calculate scores for Random Forest\n",
        "for i in range(len(fitting_values) - 1):\n",
        "    # Define the fitting value for this iteration\n",
        "    fitting_value = fitting_values[i]\n",
        "\n",
        "    # Split the data into training and testing sets with the current fitting value\n",
        "    X_train_sampled, X_test_sampled, y_train_sampled, y_test_sampled = train_test_split(\n",
        "        X, y, test_size=fitting_value, random_state=42\n",
        "    )\n",
        "\n",
        "    # Create a Random Forest model\n",
        "    rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "    # Fit the model to the training data\n",
        "    rf_model.fit(X_train_sampled, y_train_sampled)\n",
        "\n",
        "    # Predict the price change for the test data\n",
        "    rf_predictions = rf_model.predict(X_test_sampled)\n",
        "\n",
        "    # Define a threshold for predictions (e.g., 0.01 for a small price change)\n",
        "    threshold = 0.01\n",
        "\n",
        "    # Calculate the direction of the price change based on the threshold\n",
        "    y_test_direction = np.where(y_test_sampled > threshold, 1, np.where(y_test_sampled < -threshold, -1, 0))\n",
        "    predictions_direction = np.where(rf_predictions > threshold, 1, np.where(rf_predictions < -threshold, -1, 0))\n",
        "\n",
        "    # Calculate MAE and MSE for Random Forest\n",
        "    rf_mae_score = mean_absolute_error(y_test_sampled, rf_predictions)\n",
        "    rf_mse_score = mean_squared_error(y_test_sampled, rf_predictions)\n",
        "\n",
        "    # Calculate Z-score, accuracy, and precision for Random Forest\n",
        "    rf_z_score = (accuracy_score(y_test_direction, predictions_direction) - 0.5) / np.sqrt(\n",
        "        (0.5 * (1 - 0.5)) / len(y_test_sampled)\n",
        "    )\n",
        "    rf_accuracy = accuracy_score(y_test_direction, predictions_direction)\n",
        "    rf_precision = precision_score(y_test_direction, predictions_direction, average='micro')  # Use binary average\n",
        "    rf_recall = recall_score(y_test_direction, predictions_direction, average='micro')\n",
        "\n",
        "    # Append the differences to the lists for Random Forest\n",
        "    rf_mae_differences.append(rf_mae_score)\n",
        "    rf_mse_differences.append(rf_mse_score)\n",
        "    rf_z_score_differences.append(rf_z_score)\n",
        "    rf_accuracy_differences.append(rf_accuracy)\n",
        "    rf_precision_differences.append(rf_precision)\n",
        "    rf_recall_differences.append(rf_recall)\n",
        "\n",
        "# Create a line chart to visualize the differences for Random Forest\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.plot(fitting_values[:-1], rf_mae_differences, label='Random Forest MAE Difference', marker='o', color='tab:blue')\n",
        "plt.plot(fitting_values[:-1], rf_mse_differences, label='Random Forest MSE Difference', marker='o', color='tab:orange')\n",
        "plt.plot(fitting_values[:-1], rf_z_score_differences, label='Random Forest Z-Score Difference', marker='o', color='tab:green')\n",
        "plt.plot(fitting_values[:-1], rf_accuracy_differences, label='Random Forest Accuracy Difference', marker='o', color='tab:red')\n",
        "plt.plot(fitting_values[:-1], rf_precision_differences, label='Random Forest Precision Difference', marker='o', color='tab:purple')\n",
        "plt.plot(fitting_values[:-1], rf_recall_differences, label='Random Forest Recall Difference', marker='o', color='tab:brown')\n",
        "plt.xlabel('Fitting Values')\n",
        "plt.ylabel('Score Difference')\n",
        "plt.title('Score Differences for Random Forest')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vDV5tt2CZj_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM"
      ],
      "metadata": {
        "id": "6NzP3TURZXMl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P7dj5tGp5FSG"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense\n",
        "\n",
        "# Initialize empty lists to store the differences in scores for LSTM\n",
        "lstm_mae_differences = []\n",
        "lstm_mse_differences = []\n",
        "lstm_z_score_differences = []\n",
        "lstm_accuracy_differences = []\n",
        "lstm_precision_differences = []\n",
        "lstm_recall_differences = []\n",
        "\n",
        "# Loop through fitting values and calculate scores for LSTM\n",
        "for i in range(len(fitting_values) - 1):\n",
        "    # Define the fitting value for this iteration\n",
        "    fitting_value = fitting_values[i]\n",
        "\n",
        "    # Split the data into training and testing sets with the current fitting value\n",
        "    X_train_sampled, X_test_sampled, y_train_sampled, y_test_sampled = train_test_split(\n",
        "        X, y, test_size=fitting_value, random_state=42\n",
        "    )\n",
        "\n",
        "    # Reshape data for LSTM (samples, time steps, features)\n",
        "    X_train_lstm = X_train_sampled.values.reshape(X_train_sampled.shape[0], 1, X_train_sampled.shape[1])\n",
        "    X_test_lstm = X_test_sampled.values.reshape(X_test_sampled.shape[0], 1, X_test_sampled.shape[1])\n",
        "\n",
        "    # Create an LSTM model\n",
        "    lstm_model = Sequential()\n",
        "    lstm_model.add(LSTM(50, input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2])))\n",
        "    lstm_model.add(Dense(1))\n",
        "    lstm_model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "    # Fit the LSTM model to the training data\n",
        "    lstm_model.fit(X_train_lstm, y_train_sampled, epochs=50, batch_size=32, verbose=0)\n",
        "\n",
        "    # Predict the price change for the test data using the LSTM model\n",
        "    lstm_predictions = lstm_model.predict(X_test_lstm).flatten()\n",
        "\n",
        "    # Define a threshold for predictions (e.g., 0.01 for a small price change)\n",
        "    threshold = 0.01\n",
        "\n",
        "    # Calculate the direction of the price change based on the threshold\n",
        "    y_test_direction = np.where(y_test_sampled > threshold, 1, np.where(y_test_sampled < -threshold, -1, 0))\n",
        "    predictions_direction = np.where(lstm_predictions > threshold, 1, np.where(lstm_predictions < -threshold, -1, 0))\n",
        "\n",
        "    # Calculate MAE and MSE for LSTM\n",
        "    lstm_mae_score = mean_absolute_error(y_test_sampled, lstm_predictions)\n",
        "    lstm_mse_score = mean_squared_error(y_test_sampled, lstm_predictions)\n",
        "\n",
        "    # Calculate Z-score, accuracy, and precision for LSTM\n",
        "    lstm_z_score = (accuracy_score(y_test_direction, predictions_direction) - 0.5) / np.sqrt(\n",
        "        (0.5 * (1 - 0.5)) / len(y_test_sampled)\n",
        "    )\n",
        "    lstm_accuracy = accuracy_score(y_test_direction, predictions_direction)\n",
        "    lstm_precision = precision_score(y_test_direction, predictions_direction, average='micro')  # Use binary average\n",
        "    lstm_recall = recall_score(y_test_direction, predictions_direction, average='micro')\n",
        "\n",
        "    # Append the differences to the lists for LSTM\n",
        "    lstm_mae_differences.append(lstm_mae_score)\n",
        "    lstm_mse_differences.append(lstm_mse_score)\n",
        "    lstm_z_score_differences.append(lstm_z_score)\n",
        "    lstm_accuracy_differences.append(lstm_accuracy)\n",
        "    lstm_precision_differences.append(lstm_precision)\n",
        "    lstm_recall_differences.append(lstm_recall)\n",
        "\n",
        "# Create a line chart to visualize the differences for LSTM\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.plot(fitting_values[:-1], lstm_mae_differences, label='LSTM MAE Difference', marker='o', color='tab:blue')\n",
        "plt.plot(fitting_values[:-1], lstm_mse_differences, label='LSTM MSE Difference', marker='o', color='tab:orange')\n",
        "plt.plot(fitting_values[:-1], lstm_z_score_differences, label='LSTM Z-Score Difference', marker='o', color='tab:green')\n",
        "plt.plot(fitting_values[:-1], lstm_accuracy_differences, label='LSTM Accuracy Difference', marker='o', color='tab:red')\n",
        "plt.plot(fitting_values[:-1], lstm_precision_differences, label='LSTM Precision Difference', marker='o', color='tab:purple')\n",
        "plt.plot(fitting_values[:-1], lstm_recall_differences, label='LSTM Recall Difference', marker='o', color='tab:brown')\n",
        "plt.xlabel('Fitting Values')\n",
        "plt.ylabel('Score Difference')\n",
        "plt.title('Score Differences for LSTM')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PLOTTING COMPARISSON BETWEEN MODELS**"
      ],
      "metadata": {
        "id": "XEq722_OY26e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a line chart to visualize the differences with colorblind-friendly colors\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Plot Linear Regression metrics\n",
        "plt.plot(fitting_values[:-1], lr_mae_differences, label='Linear Regression MAE', marker='o', color='tab:cyan')\n",
        "plt.plot(fitting_values[:-1], lr_mse_differences, label='Linear Regression MSE', marker='o', color='tab:gray')\n",
        "plt.plot(fitting_values[:-1], lr_z_score_differences, label='Linear Regression Z-Score', marker='o', color='tab:purple')\n",
        "plt.plot(fitting_values[:-1], lr_accuracy_differences, label='Linear Regression Accuracy', marker='o', color='tab:red')\n",
        "plt.plot(fitting_values[:-1], lr_precision_differences, label='Linear Regression Precision', marker='o', color='tab:pink')\n",
        "plt.plot(fitting_values[:-1], lr_recall_differences, label='Linear Regression Recall', marker='o', color='tab:orange')\n",
        "\n",
        "# Plot Random Forest metrics\n",
        "plt.plot(fitting_values[:-1], rf_mae_differences, label='Random Forest MAE', marker='o', linestyle='dashed', color='tab:cyan')\n",
        "plt.plot(fitting_values[:-1], rf_mse_differences, label='Random Forest MSE', marker='o', linestyle='dashed', color='tab:gray')\n",
        "plt.plot(fitting_values[:-1], rf_z_score_differences, label='Random Forest Z-Score', marker='o', linestyle='dashed', color='tab:purple')\n",
        "plt.plot(fitting_values[:-1], rf_accuracy_differences, label='Random Forest Accuracy', marker='o', linestyle='dashed', color='tab:red')\n",
        "plt.plot(fitting_values[:-1], rf_precision_differences, label='Random Forest Precision', marker='o', linestyle='dashed', color='tab:pink')\n",
        "plt.plot(fitting_values[:-1], rf_recall_differences, label='Random Forest Recall', marker='o', linestyle='dashed', color='tab:orange')\n",
        "\n",
        "# Plot LSTM metrics\n",
        "plt.plot(fitting_values[:-1], lstm_mae_differences, label='LSTM MAE', marker='o', linestyle='dotted', color='tab:cyan')\n",
        "plt.plot(fitting_values[:-1], lstm_mse_differences, label='LSTM MSE', marker='o', linestyle='dotted', color='tab:gray')\n",
        "plt.plot(fitting_values[:-1], lstm_z_score_differences, label='LSTM Z-Score', marker='o', linestyle='dotted', color='tab:purple')\n",
        "plt.plot(fitting_values[:-1], lstm_accuracy_differences, label='LSTM Accuracy', marker='o', linestyle='dotted', color='tab:red')\n",
        "\n",
        "plt.xlabel('Fitting Values')\n",
        "plt.ylabel('Score Difference')\n",
        "plt.title('Score Differences for Different Models')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "WztM-pMOYzm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IMPORTING AND MERGING UP TO DATE HISTORICAL DATA**"
      ],
      "metadata": {
        "id": "_Eo2TwRB4e5r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "xvEjuiZ6B8ta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gFyyYF6M4QeG"
      },
      "outputs": [],
      "source": [
        "# Define the ticker symbol for S&P 500 (SPY is the ETF that tracks it)\n",
        "ticker_symbol = \"SPY\"\n",
        "\n",
        "# Define the start and end dates for your data\n",
        "start_date = \"2000-12-01\"\n",
        "end_date =  datetime.today().strftime('%d-%m-%Y')\n",
        "\n",
        "# Fetch historical S&P 500 data from Yahoo Finance\n",
        "sp500_data_uptodate = yf.download(ticker_symbol, start=start_date, end=end_date)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FaTEtYq34cs0"
      },
      "outputs": [],
      "source": [
        "# Replace 'YOUR_API_KEY' with your actual FRED API key\n",
        "api_key = 'YOUR API KEY HERE'\n",
        "\n",
        "# Initialize the FRED API client\n",
        "fred = Fred(api_key=api_key)\n",
        "\n",
        "# Define the series IDs for the economic indicators you want to retrieve\n",
        "inflation_series_id = 'CPIAUCSL'  # Example: Consumer Price Index for All Urban Consumers (CPI-U)\n",
        "interest_rate_series_id = 'FEDFUNDS'  # Example: Effective Federal Funds Rate\n",
        "labor_openings_series_id = 'JTSJOL'  # Example: Job Openings, Total Nonfarm\n",
        "\n",
        "# Fetch economic indicator data from FRED\n",
        "inflation_data_uptodate = fred.get_series(inflation_series_id,start=start_date, end=end_date)\n",
        "interest_rate_data_uptodate = fred.get_series(interest_rate_series_id,start=start_date, end=end_date)\n",
        "labor_openings_data_uptodate = fred.get_series(labor_openings_series_id,start=start_date, end=end_date)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the economic data Series to DataFrames with appropriate column names\n",
        "inflation_df_uptodate = pd.DataFrame({'Inflation_Rate': inflation_data})\n",
        "interest_rate_df_uptodate = pd.DataFrame({'Interest_Rate': interest_rate_data})\n",
        "labor_openings_df_uptodate = pd.DataFrame({'Labor_Openings': labor_openings_data})\n",
        "\n",
        "# Merge the DataFrames with your S&P 500 data\n",
        "merged_data_uptodate = sp500_data.join([inflation_df_uptodate, interest_rate_df_uptodate, labor_openings_df_uptodate], how='inner')"
      ],
      "metadata": {
        "id": "-taUG6pu4cb0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vO6KE_r6DjBu"
      },
      "outputs": [],
      "source": [
        "# Calculate 7-day rolling mean and standard deviation of S&P 500 prices\n",
        "merged_data_uptodate['SMA_7'] = merged_data_uptodate['Close'].rolling(window=7).mean()\n",
        "merged_data_uptodate['STD_7'] = merged_data_uptodate['Close'].rolling(window=7).std()\n",
        "\n",
        "# Calculate percentage change in S&P 500 prices\n",
        "merged_data_uptodate['Price_Change'] = merged_data_uptodate['Close'].pct_change()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WPXjSyv2DjBu"
      },
      "outputs": [],
      "source": [
        "merged_data_uptodate = merged_data_uptodate.iloc[6:]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "merged_data_uptodate.head(-1)"
      ],
      "metadata": {
        "id": "VBdcObLEExt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RUNNING LSTM MODEL ON UP TO DATE DATA WITH 0.5 FITTING**"
      ],
      "metadata": {
        "id": "DuChfc3zEAR9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping"
      ],
      "metadata": {
        "id": "dRn2CJI0U0UV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Define your features and target variable\n",
        "X = merged_data_uptodate[['SMA_7', 'STD_7', 'Inflation_Rate', 'Interest_Rate', 'Labor_Openings']]\n",
        "y = merged_data_uptodate['Price_Change']\n",
        "\n",
        "# Spliting the data into training, validation, and test sets\n",
        "# training (50%) and temporary (50%)\n",
        "X_train_temp, X_temp, y_train_temp, y_temp = train_test_split(X, y, test_size=0.5, random_state=42)\n",
        "\n",
        "# Spliting the temporary set into validation (25%) and test (25%)\n",
        "X_validation, X_test, y_validation, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Initialize the scaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit and transform the scaler on training data\n",
        "X_train_lstm = scaler.fit_transform(X_train_temp)\n",
        "\n",
        "# Transform validation and test data using the same scaler\n",
        "X_validation_lstm = scaler.transform(X_validation)\n",
        "X_test_lstm = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for LSTM (samples, time steps, features)\n",
        "num_features = X_train_temp.shape[1]  # Number of features\n",
        "X_train_lstm = X_train_lstm.reshape(X_train_temp.shape[0], 1, num_features)\n",
        "X_validation_lstm = X_validation_lstm.reshape(X_validation.shape[0], 1, num_features)\n",
        "X_test_lstm = X_test_lstm.reshape(X_test.shape[0], 1, num_features)\n",
        "\n",
        "# Create an LSTM model\n",
        "lstm_model = Sequential()\n",
        "lstm_model.add(LSTM(50, input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2])))\n",
        "lstm_model.add(Dense(1))\n",
        "lstm_model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "# Define early stopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# Fit the LSTM model to the training data and validate on the validation set\n",
        "lstm_model.fit(X_train_lstm, y_train_temp, epochs=50, validation_data=(X_validation_lstm, y_validation), callbacks=[early_stopping])\n",
        "\n",
        "# Predict the price change for the test data using the LSTM model\n",
        "lstm_predictions = lstm_model.predict(X_test_lstm).flatten()\n"
      ],
      "metadata": {
        "id": "pJ4zYtofZaCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_features = ['Inflation_Rate',\t'Interest_Rate',\t'Labor_Openings',\t'SMA_7',\t'STD_7']\n",
        "historical_data_lstm = merged_data_uptodate[selected_features].values"
      ],
      "metadata": {
        "id": "dj4pFbpNMk1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_length = 5\n",
        "historical_data_lstm = np.array([historical_data_lstm[i:i+sequence_length] for i in range(len(historical_data_lstm)-sequence_length+1)])\n",
        "\n",
        "historical_data_lstm.shape\n"
      ],
      "metadata": {
        "id": "H8yTIqWPULdQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_length = 5\n",
        "num_features = 5\n",
        "\n",
        "# Reshape the data\n",
        "historical_data_lstm = historical_data_lstm.reshape(-1, 1, num_features)\n",
        "\n",
        "# Now, historical_data_lstm should have the shape (num_samples, 1, 5)\n",
        "lstm_predictions = lstm_model.predict(historical_data_lstm)\n",
        "\n",
        "historical_data_lstm.shape"
      ],
      "metadata": {
        "id": "ktmWI1AoUsSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_predictions = lstm_model.predict(historical_data_lstm)"
      ],
      "metadata": {
        "id": "ogXUYH9DUPXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the date for which you want to make a prediction\n",
        "target_date = '2024-06-21'\n",
        "\n",
        "# Extract the prediction for the specific date (e.g., the last date in the sequence)\n",
        "predicted_price_change = lstm_predictions[-1][0]\n",
        "\n",
        "# Assuming you want to predict the Close price, you can add the predicted price change to the previous Close price\n",
        "# Access the Z-axis value directly from the NumPy array\n",
        "previous_close_price = historical_data_lstm[-1][0][0]  # Replace [0][0] with the appropriate indices for your Z-axis\n",
        "\n",
        "predicted_close_price = previous_close_price * (1 + predicted_price_change)\n",
        "\n",
        "# Print the predicted Close price for the future date\n",
        "print(f\"Predicted Close Price for {target_date}: {predicted_close_price:.2f}\")\n"
      ],
      "metadata": {
        "id": "iNIaoVElOqrq"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}